{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f484906e-f6d2-4ed5-a9e3-75f371998912",
   "metadata": {},
   "source": [
    "# Run a NN with x and $\\xi$ as the input to the NN model and second stage objective as the target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429642cc-aa1a-4c00-a906-cc7e7bd1fb90",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "756a420e-e543-405e-b33f-7c84d7744e77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from ast import literal_eval\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0091ece-a4d3-499f-b013-372a75aacdad",
   "metadata": {},
   "source": [
    "## Load the data of first stage decisions, uncertainities, instances and second stage objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "122bf3d7-2361-48d5-b880-14e222c8a74b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/ztank/scratch/user/u.rd143338/ss_from_nn/Neural_second_stage/post_train_instance_20'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b91b9984-38fe-44b2-9218-5da13236a269",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Directory of data for 10 items\n",
    "I = 20\n",
    "scen = 50\n",
    "direc = '/ztank/scratch/user/u.rd143338/ss_from_nn'\n",
    "filename = \"instance_1_250_items_\" + str(I) + \"_num_of_first_stage_11_scenarios_\" + str(scen)\n",
    "\n",
    "# path contains the location to the csv files\n",
    "path=os.path.join(direc, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16c0efa5-5d87-4911-a8c0-5a6575fb1afe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'high layers improved NN' already exists.\n"
     ]
    }
   ],
   "source": [
    "## folder to save the data\n",
    "\n",
    "def create_folder(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"Folder '{folder_path}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"Folder '{folder_path}' already exists.\")\n",
    "        \n",
    "##################################################################################        \n",
    "##################################################################################\n",
    "# Specify the folder path you want to create\n",
    "arch_date_created = \"high layers improved NN\"\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "##################################################################################\n",
    "#### this folder path is for data storage\n",
    "folder_path = os.path.join(arch_date_created)\n",
    "\n",
    "# Call the function to create the folder\n",
    "create_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2d23136-2e2d-4185-8dbb-a92f1657356e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_weights_biases_to_json(model, filename):\n",
    "    # Extract weights and biases from the model\n",
    "    weights_biases = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        weights_biases[name] = param.data.tolist()\n",
    "\n",
    "    # Save weights and biases to a JSON file\n",
    "    with open(filename, 'w') as json_file:\n",
    "        json.dump(weights_biases, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd334ea2-c4ba-4893-9c7c-52fa5c07033f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file path is at: high layers improved NN\n"
     ]
    }
   ],
   "source": [
    "print(\"Input file path is at: {}\".format(folder_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e84e866-c700-4fad-b3b9-918a5d9bbdff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'high layers improved NN'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d4624dd-3435-4092-b58e-d8bdb3b17ca6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_csv_data(folder_path):\n",
    "    # Get a list of all CSV files in the folder\n",
    "    csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "    \n",
    "    # Initialize an empty DataFrame to store combined data\n",
    "    dfs = []\n",
    "    \n",
    "    # Loop through each CSV file\n",
    "    for file in csv_files:\n",
    "        # Read the CSV file into a DataFrame\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Append the DataFrame to the combined DataFrame\n",
    "        dfs.append(df)\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "## Combined data from csv files\n",
    "combined_data = combine_csv_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9833d8c7-be79-4cfb-98b5-68d3f26aa48f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>first_stage_obj</th>\n",
       "      <th>x</th>\n",
       "      <th>r</th>\n",
       "      <th>second_stage_obj</th>\n",
       "      <th>p_bar</th>\n",
       "      <th>Reduced Capacity</th>\n",
       "      <th>t</th>\n",
       "      <th>p_hat</th>\n",
       "      <th>total_obj</th>\n",
       "      <th>y</th>\n",
       "      <th>original_capacity</th>\n",
       "      <th>w</th>\n",
       "      <th>uncern</th>\n",
       "      <th>gamma</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[786.7367467600798, 43.66934851926846, 162.193...</td>\n",
       "      <td>1926.467568</td>\n",
       "      <td>[-0.0, -0.0, -0.0, 1.0, -0.0, -0.0, -0.0, 1.0,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, -0.0, 1.0,...</td>\n",
       "      <td>-7550.168084</td>\n",
       "      <td>[659.1369113656739, 30.554869499429, 113.97742...</td>\n",
       "      <td>2934.110215</td>\n",
       "      <td>[295.2501409369704, 424.6079924086646, 103.184...</td>\n",
       "      <td>[298.010362187704, 16.585270654569555, 62.4610...</td>\n",
       "      <td>-5623.700516</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>3912.146954</td>\n",
       "      <td>[570.4489230680714, 561.4783723073962, 391.224...</td>\n",
       "      <td>[0.0709, 0.251, 0.0441, 1.0184, 0.1205, 0.3195...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[786.7367467600798, 43.66934851926846, 162.193...</td>\n",
       "      <td>1926.467568</td>\n",
       "      <td>[-0.0, -0.0, -0.0, 1.0, -0.0, -0.0, -0.0, 1.0,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>-7366.064879</td>\n",
       "      <td>[659.1369113656739, 30.554869499429, 113.97742...</td>\n",
       "      <td>2934.110215</td>\n",
       "      <td>[295.2501409369704, 424.6079924086646, 103.184...</td>\n",
       "      <td>[298.010362187704, 16.585270654569555, 62.4610...</td>\n",
       "      <td>-5439.597312</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>3912.146954</td>\n",
       "      <td>[570.4489230680714, 561.4783723073962, 391.224...</td>\n",
       "      <td>[0.0492, 0.1748, 0.1158, 0.153, 0.0711, 0.0452...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   f  first_stage_obj  \\\n",
       "0  [786.7367467600798, 43.66934851926846, 162.193...      1926.467568   \n",
       "1  [786.7367467600798, 43.66934851926846, 162.193...      1926.467568   \n",
       "\n",
       "                                                   x  \\\n",
       "0  [-0.0, -0.0, -0.0, 1.0, -0.0, -0.0, -0.0, 1.0,...   \n",
       "1  [-0.0, -0.0, -0.0, 1.0, -0.0, -0.0, -0.0, 1.0,...   \n",
       "\n",
       "                                                   r  second_stage_obj  \\\n",
       "0  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, -0.0, 1.0,...      -7550.168084   \n",
       "1  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, ...      -7366.064879   \n",
       "\n",
       "                                               p_bar  Reduced Capacity  \\\n",
       "0  [659.1369113656739, 30.554869499429, 113.97742...       2934.110215   \n",
       "1  [659.1369113656739, 30.554869499429, 113.97742...       2934.110215   \n",
       "\n",
       "                                                   t  \\\n",
       "0  [295.2501409369704, 424.6079924086646, 103.184...   \n",
       "1  [295.2501409369704, 424.6079924086646, 103.184...   \n",
       "\n",
       "                                               p_hat    total_obj  \\\n",
       "0  [298.010362187704, 16.585270654569555, 62.4610... -5623.700516   \n",
       "1  [298.010362187704, 16.585270654569555, 62.4610... -5439.597312   \n",
       "\n",
       "                                                   y  original_capacity  \\\n",
       "0  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, ...        3912.146954   \n",
       "1  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, ...        3912.146954   \n",
       "\n",
       "                                                   w  \\\n",
       "0  [570.4489230680714, 561.4783723073962, 391.224...   \n",
       "1  [570.4489230680714, 561.4783723073962, 391.224...   \n",
       "\n",
       "                                              uncern  gamma  seed  \n",
       "0  [0.0709, 0.251, 0.0441, 1.0184, 0.1205, 0.3195...    4.0    32  \n",
       "1  [0.0492, 0.1748, 0.1158, 0.153, 0.0711, 0.0452...    4.0    32  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d6e97e-aa58-434c-9d97-06be4c8f6095",
   "metadata": {},
   "source": [
    "## Shuffle the dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95942b47-44a7-4a27-84e4-32e4646a3c52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f</th>\n",
       "      <th>first_stage_obj</th>\n",
       "      <th>x</th>\n",
       "      <th>r</th>\n",
       "      <th>second_stage_obj</th>\n",
       "      <th>p_bar</th>\n",
       "      <th>Reduced Capacity</th>\n",
       "      <th>t</th>\n",
       "      <th>p_hat</th>\n",
       "      <th>total_obj</th>\n",
       "      <th>y</th>\n",
       "      <th>original_capacity</th>\n",
       "      <th>w</th>\n",
       "      <th>uncern</th>\n",
       "      <th>gamma</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[668.3026011818135, 1287.8562336053396, 538.67...</td>\n",
       "      <td>2407.90594</td>\n",
       "      <td>[1.0, 0.0, -0.0, 1.0, -0.0, 1.0, 1.0, -0.0, -0...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 1.0, 0.0, -0.0, -0.0, 0.0, 0.0...</td>\n",
       "      <td>-9058.417905</td>\n",
       "      <td>[527.5306212418371, 923.419571417487, 401.5972...</td>\n",
       "      <td>2840.612347</td>\n",
       "      <td>[36.299713207101334, 229.23908585200888, 142.2...</td>\n",
       "      <td>[256.3094599686253, 442.5731412958027, 207.114...</td>\n",
       "      <td>-6650.511965</td>\n",
       "      <td>[1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>3341.896879</td>\n",
       "      <td>[301.98683454640326, 768.1277137348278, 485.34...</td>\n",
       "      <td>[0.0272, 0.0967, 0.5364, 0.0202, 0.0663, 0.039...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[703.0926362237493, 1186.4954312719087, 283.71...</td>\n",
       "      <td>1862.06151</td>\n",
       "      <td>[-0.0, 1.0, -0.0, 1.0, -0.0, -0.0, 1.0, -0.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>-9037.251754</td>\n",
       "      <td>[561.4235703171213, 913.832777448831, 219.6439...</td>\n",
       "      <td>3073.338103</td>\n",
       "      <td>[642.5177086820069, 151.71523729802115, 224.39...</td>\n",
       "      <td>[263.86371393025183, 438.9654149836514, 99.269...</td>\n",
       "      <td>-7175.190244</td>\n",
       "      <td>[0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>3414.820114</td>\n",
       "      <td>[942.9299427166219, 624.6242716623353, 296.082...</td>\n",
       "      <td>[0.1447, 0.4878, 0.2543, 0.1594, 0.2792, 0.006...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   f  first_stage_obj  \\\n",
       "0  [668.3026011818135, 1287.8562336053396, 538.67...       2407.90594   \n",
       "1  [703.0926362237493, 1186.4954312719087, 283.71...       1862.06151   \n",
       "\n",
       "                                                   x  \\\n",
       "0  [1.0, 0.0, -0.0, 1.0, -0.0, 1.0, 1.0, -0.0, -0...   \n",
       "1  [-0.0, 1.0, -0.0, 1.0, -0.0, -0.0, 1.0, -0.0, ...   \n",
       "\n",
       "                                                   r  second_stage_obj  \\\n",
       "0  [1.0, 0.0, 0.0, 1.0, 0.0, -0.0, -0.0, 0.0, 0.0...      -9058.417905   \n",
       "1  [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      -9037.251754   \n",
       "\n",
       "                                               p_bar  Reduced Capacity  \\\n",
       "0  [527.5306212418371, 923.419571417487, 401.5972...       2840.612347   \n",
       "1  [561.4235703171213, 913.832777448831, 219.6439...       3073.338103   \n",
       "\n",
       "                                                   t  \\\n",
       "0  [36.299713207101334, 229.23908585200888, 142.2...   \n",
       "1  [642.5177086820069, 151.71523729802115, 224.39...   \n",
       "\n",
       "                                               p_hat    total_obj  \\\n",
       "0  [256.3094599686253, 442.5731412958027, 207.114... -6650.511965   \n",
       "1  [263.86371393025183, 438.9654149836514, 99.269... -7175.190244   \n",
       "\n",
       "                                                   y  original_capacity  \\\n",
       "0  [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, ...        3341.896879   \n",
       "1  [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...        3414.820114   \n",
       "\n",
       "                                                   w  \\\n",
       "0  [301.98683454640326, 768.1277137348278, 485.34...   \n",
       "1  [942.9299427166219, 624.6242716623353, 296.082...   \n",
       "\n",
       "                                              uncern  gamma  seed  \n",
       "0  [0.0272, 0.0967, 0.5364, 0.0202, 0.0663, 0.039...    2.0    70  \n",
       "1  [0.1447, 0.4878, 0.2543, 0.1594, 0.2792, 0.006...    4.0   192  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use only seed from 1 to 200 for training\n",
    "combined_data = combined_data[combined_data[\"seed\"]<=200]\n",
    "shuffle_seed = 1\n",
    "training_data=combined_data.sample(frac=1, random_state=shuffle_seed).reset_index(drop=True)\n",
    "training_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15156b97-a7e3-4a36-ac91-4439ba8e0148",
   "metadata": {},
   "source": [
    "## The element list of the dataframe is split and new dataframe for instances, X and uncertainities are formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d61c9ef3-5de1-4686-94eb-d6241fbb9a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## The cells have list, make one column for each member of the list\n",
    "def split_list_column(df, col_name):\n",
    "    col=df[col_name].apply(literal_eval).apply(pd.Series)\n",
    "    new_columns = [f'{col_name}_{i}' for i in range(1,len(col.columns)+1)]\n",
    "    col.columns=new_columns\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b9e58ed-206f-43a7-b9bf-bcfe7b3c9a3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instance parameter that define a knapsack problem, these words will be used as a prefic for the columns generated by the elements of the list\n",
    "instance_parameter = ['f', 'p_bar', 't', 'p_hat', 'original_capacity', 'w', 'gamma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcf14ad8-00c3-4af4-9ad2-9860817526f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_df=pd.DataFrame()\n",
    "for i in instance_parameter:\n",
    "    if i!='original_capacity' and i!='gamma':\n",
    "        instance_df=pd.concat([instance_df, split_list_column(training_data,i)], axis=1)\n",
    "    else:\n",
    "        instance_df=pd.concat([instance_df, training_data[i]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c303ab55-7079-4da6-bd40-80da07ba9e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110000, 102)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4630b5a-1b2c-46d8-b01c-68d06ac20b27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_bar_1</th>\n",
       "      <th>p_bar_2</th>\n",
       "      <th>p_bar_3</th>\n",
       "      <th>p_bar_4</th>\n",
       "      <th>p_bar_5</th>\n",
       "      <th>p_bar_6</th>\n",
       "      <th>p_bar_7</th>\n",
       "      <th>p_bar_8</th>\n",
       "      <th>p_bar_9</th>\n",
       "      <th>p_bar_10</th>\n",
       "      <th>p_bar_11</th>\n",
       "      <th>p_bar_12</th>\n",
       "      <th>p_bar_13</th>\n",
       "      <th>p_bar_14</th>\n",
       "      <th>p_bar_15</th>\n",
       "      <th>p_bar_16</th>\n",
       "      <th>p_bar_17</th>\n",
       "      <th>p_bar_18</th>\n",
       "      <th>p_bar_19</th>\n",
       "      <th>p_bar_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>527.530621</td>\n",
       "      <td>923.419571</td>\n",
       "      <td>401.597263</td>\n",
       "      <td>601.986693</td>\n",
       "      <td>973.604434</td>\n",
       "      <td>281.057600</td>\n",
       "      <td>746.491479</td>\n",
       "      <td>192.692532</td>\n",
       "      <td>439.342751</td>\n",
       "      <td>583.819419</td>\n",
       "      <td>94.037998</td>\n",
       "      <td>545.867703</td>\n",
       "      <td>439.227213</td>\n",
       "      <td>935.126780</td>\n",
       "      <td>200.056757</td>\n",
       "      <td>404.037751</td>\n",
       "      <td>898.655196</td>\n",
       "      <td>895.128889</td>\n",
       "      <td>429.041162</td>\n",
       "      <td>832.264044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>561.423570</td>\n",
       "      <td>913.832777</td>\n",
       "      <td>219.643966</td>\n",
       "      <td>475.713350</td>\n",
       "      <td>193.920942</td>\n",
       "      <td>50.703086</td>\n",
       "      <td>870.473152</td>\n",
       "      <td>169.655321</td>\n",
       "      <td>744.802975</td>\n",
       "      <td>672.477532</td>\n",
       "      <td>710.186987</td>\n",
       "      <td>206.553695</td>\n",
       "      <td>889.163072</td>\n",
       "      <td>965.945607</td>\n",
       "      <td>118.752765</td>\n",
       "      <td>805.729976</td>\n",
       "      <td>63.063472</td>\n",
       "      <td>980.607714</td>\n",
       "      <td>490.019986</td>\n",
       "      <td>690.109213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      p_bar_1     p_bar_2     p_bar_3     p_bar_4     p_bar_5     p_bar_6  \\\n",
       "0  527.530621  923.419571  401.597263  601.986693  973.604434  281.057600   \n",
       "1  561.423570  913.832777  219.643966  475.713350  193.920942   50.703086   \n",
       "\n",
       "      p_bar_7     p_bar_8     p_bar_9    p_bar_10    p_bar_11    p_bar_12  \\\n",
       "0  746.491479  192.692532  439.342751  583.819419   94.037998  545.867703   \n",
       "1  870.473152  169.655321  744.802975  672.477532  710.186987  206.553695   \n",
       "\n",
       "     p_bar_13    p_bar_14    p_bar_15    p_bar_16    p_bar_17    p_bar_18  \\\n",
       "0  439.227213  935.126780  200.056757  404.037751  898.655196  895.128889   \n",
       "1  889.163072  965.945607  118.752765  805.729976   63.063472  980.607714   \n",
       "\n",
       "     p_bar_19    p_bar_20  \n",
       "0  429.041162  832.264044  \n",
       "1  490.019986  690.109213  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_bar = instance_df.loc[: , instance_df.columns.str.startswith('p_bar')].reset_index(drop=True)\n",
    "p_bar.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f58e30f2-234f-4bca-9613-96afffcec432",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>f_10</th>\n",
       "      <th>f_11</th>\n",
       "      <th>f_12</th>\n",
       "      <th>f_13</th>\n",
       "      <th>f_14</th>\n",
       "      <th>f_15</th>\n",
       "      <th>f_16</th>\n",
       "      <th>f_17</th>\n",
       "      <th>f_18</th>\n",
       "      <th>f_19</th>\n",
       "      <th>f_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>668.302601</td>\n",
       "      <td>1287.856234</td>\n",
       "      <td>538.675378</td>\n",
       "      <td>851.961267</td>\n",
       "      <td>1206.810584</td>\n",
       "      <td>317.726331</td>\n",
       "      <td>1028.294226</td>\n",
       "      <td>251.171090</td>\n",
       "      <td>511.985739</td>\n",
       "      <td>719.841161</td>\n",
       "      <td>113.234803</td>\n",
       "      <td>634.827844</td>\n",
       "      <td>637.323233</td>\n",
       "      <td>1133.082635</td>\n",
       "      <td>237.480672</td>\n",
       "      <td>480.385927</td>\n",
       "      <td>1336.758191</td>\n",
       "      <td>1299.972628</td>\n",
       "      <td>553.383710</td>\n",
       "      <td>1188.579139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>703.092636</td>\n",
       "      <td>1186.495431</td>\n",
       "      <td>283.715212</td>\n",
       "      <td>611.909800</td>\n",
       "      <td>224.091454</td>\n",
       "      <td>68.136526</td>\n",
       "      <td>1176.598004</td>\n",
       "      <td>238.010931</td>\n",
       "      <td>997.537363</td>\n",
       "      <td>854.939961</td>\n",
       "      <td>1019.436797</td>\n",
       "      <td>269.306064</td>\n",
       "      <td>1015.967665</td>\n",
       "      <td>1244.503420</td>\n",
       "      <td>164.074143</td>\n",
       "      <td>1086.553392</td>\n",
       "      <td>74.766895</td>\n",
       "      <td>1078.941370</td>\n",
       "      <td>585.277262</td>\n",
       "      <td>894.657645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          f_1          f_2         f_3         f_4          f_5         f_6  \\\n",
       "0  668.302601  1287.856234  538.675378  851.961267  1206.810584  317.726331   \n",
       "1  703.092636  1186.495431  283.715212  611.909800   224.091454   68.136526   \n",
       "\n",
       "           f_7         f_8         f_9        f_10         f_11        f_12  \\\n",
       "0  1028.294226  251.171090  511.985739  719.841161   113.234803  634.827844   \n",
       "1  1176.598004  238.010931  997.537363  854.939961  1019.436797  269.306064   \n",
       "\n",
       "          f_13         f_14        f_15         f_16         f_17  \\\n",
       "0   637.323233  1133.082635  237.480672   480.385927  1336.758191   \n",
       "1  1015.967665  1244.503420  164.074143  1086.553392    74.766895   \n",
       "\n",
       "          f_18        f_19         f_20  \n",
       "0  1299.972628  553.383710  1188.579139  \n",
       "1  1078.941370  585.277262   894.657645  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = instance_df.loc[: , instance_df.columns.str.startswith('f')].reset_index(drop=True)\n",
    "f.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff947f79-a697-462b-b11b-d532f0f0bff0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>x_10</th>\n",
       "      <th>x_11</th>\n",
       "      <th>x_12</th>\n",
       "      <th>x_13</th>\n",
       "      <th>x_14</th>\n",
       "      <th>x_15</th>\n",
       "      <th>x_16</th>\n",
       "      <th>x_17</th>\n",
       "      <th>x_18</th>\n",
       "      <th>x_19</th>\n",
       "      <th>x_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x_1  x_2  x_3  x_4  x_5  x_6  x_7  x_8  x_9  x_10  x_11  x_12  x_13  x_14  \\\n",
       "0  1.0  0.0 -0.0  1.0 -0.0  1.0  1.0 -0.0 -0.0   1.0  -0.0   1.0   1.0  -0.0   \n",
       "1 -0.0  1.0 -0.0  1.0 -0.0 -0.0  1.0 -0.0 -0.0  -0.0  -0.0   1.0   1.0   1.0   \n",
       "\n",
       "   x_15  x_16  x_17  x_18  x_19  x_20  \n",
       "0  -0.0   1.0   1.0   1.0  -0.0   1.0  \n",
       "1  -0.0   1.0  -0.0   1.0   1.0   1.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df=split_list_column(training_data, \"x\")\n",
    "X_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "222f9bff-70a3-46bd-8d24-cde0c3efacc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uncern_1</th>\n",
       "      <th>uncern_2</th>\n",
       "      <th>uncern_3</th>\n",
       "      <th>uncern_4</th>\n",
       "      <th>uncern_5</th>\n",
       "      <th>uncern_6</th>\n",
       "      <th>uncern_7</th>\n",
       "      <th>uncern_8</th>\n",
       "      <th>uncern_9</th>\n",
       "      <th>uncern_10</th>\n",
       "      <th>uncern_11</th>\n",
       "      <th>uncern_12</th>\n",
       "      <th>uncern_13</th>\n",
       "      <th>uncern_14</th>\n",
       "      <th>uncern_15</th>\n",
       "      <th>uncern_16</th>\n",
       "      <th>uncern_17</th>\n",
       "      <th>uncern_18</th>\n",
       "      <th>uncern_19</th>\n",
       "      <th>uncern_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0967</td>\n",
       "      <td>0.5364</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0663</td>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.0785</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.1290</td>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.0894</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0703</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.2126</td>\n",
       "      <td>0.2223</td>\n",
       "      <td>0.0617</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.0531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1447</td>\n",
       "      <td>0.4878</td>\n",
       "      <td>0.2543</td>\n",
       "      <td>0.1594</td>\n",
       "      <td>0.2792</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0691</td>\n",
       "      <td>0.6022</td>\n",
       "      <td>0.0814</td>\n",
       "      <td>0.0945</td>\n",
       "      <td>0.4163</td>\n",
       "      <td>0.2567</td>\n",
       "      <td>0.3548</td>\n",
       "      <td>0.0313</td>\n",
       "      <td>0.0237</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.3127</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>0.1163</td>\n",
       "      <td>0.0024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uncern_1  uncern_2  uncern_3  uncern_4  uncern_5  uncern_6  uncern_7  \\\n",
       "0    0.0272    0.0967    0.5364    0.0202    0.0663    0.0391    0.0785   \n",
       "1    0.1447    0.4878    0.2543    0.1594    0.2792    0.0064    0.0691   \n",
       "\n",
       "   uncern_8  uncern_9  uncern_10  uncern_11  uncern_12  uncern_13  uncern_14  \\\n",
       "0    0.0272    0.1290     0.0228     0.0894     0.0080     0.0623     0.0703   \n",
       "1    0.6022    0.0814     0.0945     0.4163     0.2567     0.3548     0.0313   \n",
       "\n",
       "   uncern_15  uncern_16  uncern_17  uncern_18  uncern_19  uncern_20  \n",
       "0     0.0384     0.2126     0.2223     0.0617     0.0655     0.0531  \n",
       "1     0.0237     0.0322     0.3127     0.0898     0.1163     0.0024  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Uncer_df=split_list_column(training_data, \"uncern\")\n",
    "Uncer_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2531c068-8a30-4124-b895-f39df24402f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         -6650.511965\n",
       "1         -7175.190244\n",
       "2         -6853.433127\n",
       "3         -4872.761981\n",
       "4        -11154.401175\n",
       "              ...     \n",
       "109995    -8932.247559\n",
       "109996    -8977.719958\n",
       "109997    -8084.886084\n",
       "109998    -7960.723633\n",
       "109999   -10088.266736\n",
       "Name: total_obj, Length: 110000, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target=training_data[\"total_obj\"]\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6786894f-799e-44b4-a9d2-ebdc137f94d0",
   "metadata": {},
   "source": [
    "## Neural Network Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb7dd441-1e40-4940-9aec-378f6de6adfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -6650.51196482,  -7175.19024388,  -6853.43312693, ...,\n",
       "        -8084.88608393,  -7960.72363269, -10088.2667364 ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert target column to numpy array\n",
    "target_array = target.values\n",
    "target_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b17efcc2-9edf-441c-9a1b-dbf689adc714",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## For instance = 20\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        ## Dont change these values\n",
    "        # self.embedding_instance = nn.Linear(102, 128)\n",
    "        # self.embedding_X = nn.Linear(20, 15)\n",
    "        # self.embedding_uncern = nn.Linear(20, 15)\n",
    "        # self.fc1 = nn.Linear(158, 54)\n",
    "        # self.fc2 = nn.Linear(54, 32)  \n",
    "        # self.fc3 = nn.Linear(32, 8)\n",
    "        # self.fc4 = nn.Linear(8,1)\n",
    "        \n",
    "        self.embedding_instance = nn.Linear(102, 228)\n",
    "        self.embedding_X = nn.Linear(20, 30)\n",
    "        self.embedding_uncern = nn.Linear(20, 30)\n",
    "        self.fc1 = nn.Linear(288, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)  \n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.fc5 = nn.Linear(32, 10)\n",
    "        self.fc6 = nn.Linear(10,1)\n",
    "\n",
    "\n",
    "    def forward(self, instance, X, uncern):\n",
    "        # instance_embed = torch.relu(self.embedding_instance(instance))\n",
    "        # X_embed = torch.relu(self.embedding_X(X))\n",
    "        # uncern_embed = torch.relu(self.embedding_uncern(uncern))\n",
    "        # concatenated = torch.cat((instance_embed, X_embed, uncern_embed), dim=1)\n",
    "        \n",
    "        concatenated = torch.cat((self.embedding_instance(instance),self.embedding_X(X), self.embedding_uncern(uncern)), dim=1)\n",
    "        \n",
    "        output = torch.relu(self.fc1(concatenated))\n",
    "        output = torch.relu(self.fc2(output))\n",
    "        output = torch.relu(self.fc3(output))\n",
    "        output = torch.relu(self.fc4(output))\n",
    "        output = torch.relu(self.fc5(output))\n",
    "        output = self.fc6(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47344739-fa2b-4af9-8c76-6a04b4f1ef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "instance_train, instance_test, \\\n",
    "X_train, X_test, \\\n",
    "uncern_train, uncern_test, \\\n",
    "target_train, target_test = train_test_split(instance_df.values, X_df.values, Uncer_df.values, target_array, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e54cbc1-0dff-4cce-9720-3ec7fa8e00dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Since the X_train is always scaled between 0 or 1, here we shall just scale the values of the intsnace_train and uncern_train. Once this is achieved, we will get the values of x_min and x_max from the training set which we wil further use to scale the values of the testing set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6da62910-d89d-47ac-af57-2154c1aa65f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler_instance = MinMaxScaler()\n",
    "scaler_instance.fit(instance_train)\n",
    "instance_train_transformed = scaler_instance.transform(instance_train)\n",
    "instance_test_transformed = scaler_instance.transform(instance_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5cae7b4b-b392-4868-830b-ac7f7dab1edb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler_uncern = MinMaxScaler()\n",
    "scaler_uncern.fit(uncern_train)\n",
    "uncern_train_transformed = scaler_uncern.transform(uncern_train)\n",
    "uncern_test_transformed = scaler_uncern.transform(uncern_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "068cafd7-fb11-4ffa-a060-73b89248636a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler_target = MinMaxScaler()\n",
    "scaler_target.fit(target_train.reshape(-1,1))\n",
    "target_train_transformed = scaler_target.transform(target_train.reshape(-1,1))\n",
    "target_test_transformed = scaler_target.transform(target_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b77128ff-f3d6-453d-9dc0-53e6c34f796c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file created successfully!\n"
     ]
    }
   ],
   "source": [
    "min_max_scalers={}\n",
    "min_max_scalers[\"scaler_instance.data_max_\"]=scaler_instance.data_max_.tolist()\n",
    "min_max_scalers[\"scaler_instance.data_min_\"]=scaler_instance.data_min_.tolist()\n",
    "min_max_scalers[\"scaler_uncern.data_max_\"]=scaler_uncern.data_max_.tolist()\n",
    "min_max_scalers[\"scaler_uncern.data_min_\"]=scaler_uncern.data_min_.tolist()\n",
    "min_max_scalers[\"scaler_target.data_max_\"]=scaler_target.data_max_.tolist()\n",
    "min_max_scalers[\"scaler_target.data_min_\"]=scaler_target.data_min_.tolist()\n",
    "\n",
    "file_name = \"min_max_scalers_inst_\" + str(I) + \".json\"\n",
    "file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "# Write dictionary to JSON file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(min_max_scalers, json_file)\n",
    "\n",
    "print(\"JSON file created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4747cbaa-98e7-44fa-8675-0fcee6168707",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/ztank/scratch/user/u.rd143338/ss_from_nn/Neural_second_stage/post_train_instance_20'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2dafedd-5394-42fe-9874-751cc5b30b31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'high layers improved NN'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55c11246-abe4-4492-b2af-2fa2eec0bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy arrays to PyTorch tensors\n",
    "instance_train_tensor = torch.tensor(instance_train_transformed, dtype=torch.float32)\n",
    "instance_test_tensor = torch.tensor(instance_test_transformed, dtype=torch.float32)\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "uncern_train_tensor = torch.tensor(uncern_train_transformed, dtype=torch.float32)\n",
    "uncern_test_tensor = torch.tensor(uncern_test_transformed, dtype=torch.float32)\n",
    "target_train_tensor = torch.tensor(target_train_transformed, dtype=torch.float32)\n",
    "target_test_tensor = torch.tensor(target_test_transformed, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b43d4d91-f305-4d86-a876-525eca11a798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test datasets\n",
    "train_dataset = TensorDataset(instance_train_tensor, X_train_tensor, uncern_train_tensor, target_train_tensor)\n",
    "test_dataset = TensorDataset(instance_test_tensor, X_test_tensor, uncern_test_tensor, target_test_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ae03941-6a9c-4c86-9567-32ecf0a68c15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a2385fe-4f3c-4d3d-a3f1-2fea85c3b35d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Move model to GPU\n",
    "model = MyModel().to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "# Create training and test data loaders\n",
    "batch_size = 512\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27d2bbe5-4314-4216-a18e-854057928c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] epoch_loss: 0.000004 batch_loss: 0.000003 batch_mae: 0.001272\n",
      "True MAE: 11.941164 , True MAPE: 0.160084 \n",
      "[1] Training MAE: 0.001387 ***Validation*** MAE: 0.002969 #######  True MAE on test batch 10.670 , True MAPE on test batch 0.142\n",
      "Epoch 00032: reducing learning rate of group 0 to 9.0000e-04.\n",
      "Epoch 00063: reducing learning rate of group 0 to 8.1000e-04.\n",
      "Epoch 00094: reducing learning rate of group 0 to 7.2900e-04.\n",
      "[101,   100] epoch_loss: 0.000002 batch_loss: 0.000003 batch_mae: 0.001406\n",
      "True MAE: 13.197083 , True MAPE: 0.187167 \n",
      "[101] Training MAE: 0.001156 ***Validation*** MAE: 0.002941 #######  True MAE on test batch 9.662 , True MAPE on test batch 0.135\n",
      "Epoch 00125: reducing learning rate of group 0 to 6.5610e-04.\n",
      "Epoch 00156: reducing learning rate of group 0 to 5.9049e-04.\n",
      "Epoch 00187: reducing learning rate of group 0 to 5.3144e-04.\n",
      "[201,   100] epoch_loss: 0.000002 batch_loss: 0.000003 batch_mae: 0.001280\n",
      "True MAE: 12.018722 , True MAPE: 0.170851 \n",
      "[201] Training MAE: 0.001069 ***Validation*** MAE: 0.002914 #######  True MAE on test batch 8.655 , True MAPE on test batch 0.120\n",
      "Epoch 00218: reducing learning rate of group 0 to 4.7830e-04.\n",
      "Epoch 00249: reducing learning rate of group 0 to 4.3047e-04.\n",
      "Epoch 00280: reducing learning rate of group 0 to 3.8742e-04.\n",
      "[301,   100] epoch_loss: 0.000002 batch_loss: 0.000002 batch_mae: 0.001063\n",
      "True MAE: 9.981364 , True MAPE: 0.136664 \n",
      "[301] Training MAE: 0.001025 ***Validation*** MAE: 0.002900 #######  True MAE on test batch 7.965 , True MAPE on test batch 0.111\n",
      "Epoch 00311: reducing learning rate of group 0 to 3.4868e-04.\n",
      "Epoch 00342: reducing learning rate of group 0 to 3.1381e-04.\n",
      "Epoch 00373: reducing learning rate of group 0 to 2.8243e-04.\n",
      "[401,   100] epoch_loss: 0.000002 batch_loss: 0.000002 batch_mae: 0.001032\n",
      "True MAE: 9.690556 , True MAPE: 0.132815 \n",
      "[401] Training MAE: 0.001000 ***Validation*** MAE: 0.002890 #######  True MAE on test batch 7.788 , True MAPE on test batch 0.108\n",
      "Epoch 00404: reducing learning rate of group 0 to 2.5419e-04.\n",
      "Epoch 00435: reducing learning rate of group 0 to 2.2877e-04.\n",
      "Epoch 00466: reducing learning rate of group 0 to 2.0589e-04.\n",
      "Epoch 00497: reducing learning rate of group 0 to 1.8530e-04.\n",
      "[501,   100] epoch_loss: 0.000002 batch_loss: 0.000002 batch_mae: 0.001012\n",
      "True MAE: 9.496984 , True MAPE: 0.129998 \n",
      "[501] Training MAE: 0.000986 ***Validation*** MAE: 0.002878 #######  True MAE on test batch 7.906 , True MAPE on test batch 0.109\n",
      "Epoch 00528: reducing learning rate of group 0 to 1.6677e-04.\n",
      "Epoch 00559: reducing learning rate of group 0 to 1.5009e-04.\n",
      "Epoch 00590: reducing learning rate of group 0 to 1.3509e-04.\n",
      "[601,   100] epoch_loss: 0.000002 batch_loss: 0.000002 batch_mae: 0.001037\n",
      "True MAE: 9.732914 , True MAPE: 0.134136 \n",
      "[601] Training MAE: 0.000968 ***Validation*** MAE: 0.002862 #######  True MAE on test batch 7.550 , True MAPE on test batch 0.104\n",
      "Epoch 00621: reducing learning rate of group 0 to 1.2158e-04.\n",
      "Epoch 00652: reducing learning rate of group 0 to 1.0942e-04.\n",
      "Epoch 00683: reducing learning rate of group 0 to 9.8477e-05.\n",
      "[701,   100] epoch_loss: 0.000002 batch_loss: 0.000002 batch_mae: 0.001006\n",
      "True MAE: 9.444554 , True MAPE: 0.130157 \n",
      "[701] Training MAE: 0.000953 ***Validation*** MAE: 0.002853 #######  True MAE on test batch 7.536 , True MAPE on test batch 0.104\n",
      "Epoch 00714: reducing learning rate of group 0 to 8.8629e-05.\n",
      "Epoch 00745: reducing learning rate of group 0 to 7.9766e-05.\n",
      "Epoch 00776: reducing learning rate of group 0 to 7.1790e-05.\n",
      "[801,   100] epoch_loss: 0.000002 batch_loss: 0.000002 batch_mae: 0.000991\n",
      "True MAE: 9.300784 , True MAPE: 0.128171 \n",
      "[801] Training MAE: 0.000943 ***Validation*** MAE: 0.002849 #######  True MAE on test batch 7.379 , True MAPE on test batch 0.102\n",
      "Epoch 00807: reducing learning rate of group 0 to 6.4611e-05.\n",
      "Epoch 00838: reducing learning rate of group 0 to 5.8150e-05.\n",
      "Epoch 00899: reducing learning rate of group 0 to 5.2335e-05.\n",
      "[901,   100] epoch_loss: 0.000002 batch_loss: 0.000002 batch_mae: 0.000959\n",
      "True MAE: 9.006236 , True MAPE: 0.123800 \n",
      "[901] Training MAE: 0.000939 ***Validation*** MAE: 0.002834 #######  True MAE on test batch 7.276 , True MAPE on test batch 0.101\n",
      "Epoch 00940: reducing learning rate of group 0 to 4.7101e-05.\n",
      "Epoch 00971: reducing learning rate of group 0 to 4.2391e-05.\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adamax(model.parameters(), lr=0.01)\n",
    "\n",
    "# Define learning rate scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=50, verbose=True)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    running_mae = 0.0  # Initialize running MAE\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs_instance, inputs_X, inputs_uncern, labels = data\n",
    "        # Move tensors to GPU\n",
    "        inputs_instance, inputs_X, inputs_uncern, labels = inputs_instance.to(device), inputs_X.to(device), inputs_uncern.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs_instance, inputs_X, inputs_uncern)\n",
    "        loss = criterion(outputs, labels.view(-1, 1))  # Assuming labels is a column vector\n",
    "        \n",
    "        # Calculate Mean Absolute Error (MAE)\n",
    "        mae = torch.mean(torch.abs(outputs - labels.view(-1, 1)))\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        running_mae += mae.item()  # Accumulate MAE\n",
    "        \n",
    "        ######## Print the true loss on the inverse transformed variables\n",
    "        \n",
    "        ############################################################################\n",
    "        outputs_invtransformed = scaler_target.inverse_transform(outputs.cpu().detach().numpy())\n",
    "        labels_invtransformed = scaler_target.inverse_transform(labels.view(-1, 1).cpu().detach().numpy())\n",
    "        outputs_invtransformed = outputs_invtransformed.flatten()\n",
    "        labels_invtransformed = labels_invtransformed.flatten()\n",
    "        # Calculate MSE\n",
    "        mae_invtransformed = np.mean(np.abs(outputs_invtransformed - labels_invtransformed))\n",
    "        # Calculate MAPE\n",
    "        mape_invtransformed = np.mean(np.abs((outputs_invtransformed - labels_invtransformed) /labels_invtransformed)) * 100\n",
    "        #############################################################################\n",
    "        \n",
    "        \n",
    "        if epoch % 100 == 0 and (i + 1) % 100 == 0:  # Print every 100 epochs and 100th mini-batch\n",
    "            print('[%d, %5d] epoch_loss: %.6f batch_loss: %.6f batch_mae: %.6f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100, loss.item(), mae.item()))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            print('True MAE: %.6f , True MAPE: %.6f '%\n",
    "                 (mae_invtransformed, mape_invtransformed))\n",
    "    \n",
    "        ############################################################################\n",
    "    \n",
    "    # Perform validation and adjust learning rate\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        test_mae = 0.0\n",
    "        mae_invtransformed_test = 0.0\n",
    "        mape_invtransformed_test = 0.0\n",
    "        for data in test_loader:\n",
    "            inputs_instance, inputs_X, inputs_uncern, labels = data\n",
    "            # Move tensors to GPU\n",
    "            inputs_instance, inputs_X, inputs_uncern, labels = inputs_instance.to(device), inputs_X.to(device), inputs_uncern.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs_instance, inputs_X, inputs_uncern)\n",
    "            test_loss += criterion(outputs, labels.view(-1, 1)).item()\n",
    "            test_mae += torch.mean(torch.abs(outputs - labels.view(-1, 1))).item()  # Calculate MAE for test set\n",
    "            \n",
    "            ####################################################################################\n",
    "            outputs_invtransformed_test = scaler_target.inverse_transform(outputs.cpu().detach().numpy())\n",
    "            labels_invtransformed_test = scaler_target.inverse_transform(labels.view(-1, 1).cpu().detach().numpy())\n",
    "            outputs_invtransformed_test = outputs_invtransformed.flatten()\n",
    "            labels_invtransformed_test = labels_invtransformed.flatten()\n",
    "            # Calculate MSE\n",
    "            mae_invtransformed_test += np.mean(np.abs(outputs_invtransformed_test - labels_invtransformed_test))\n",
    "            # Calculate MAPE\n",
    "            mape_invtransformed_test += np.mean(np.abs((outputs_invtransformed_test - labels_invtransformed_test) /labels_invtransformed_test)) * 100\n",
    "            \n",
    "            ####################################################################################\n",
    "            \n",
    "        scheduler.step(test_loss)\n",
    "        \n",
    "    if epoch % 100 == 0:  # Print every 100 epochs\n",
    "        print('[%d] Training MAE: %.6f ***Validation*** MAE: %.6f #######  True MAE on test batch %.3f , True MAPE on test batch %.3f' % (epoch + 1, running_mae / len(train_loader), test_mae / len(test_loader), mae_invtransformed_test/len(test_loader), mape_invtransformed_test/len(test_loader)))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87feac63-fb8a-4a9e-9992-ab03ff721c2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights saved successfully at: high layers improved NN/model_weights_20_instance_50_scen.pth\n"
     ]
    }
   ],
   "source": [
    "# Specify the file path where you want to save the model weights\n",
    "\n",
    "weights_path = \"model_weights_\" + str(I) + \"_instance_\" + str(scen) + \"_scen.pth\"\n",
    "file_path =os.path.join(folder_path, weights_path)\n",
    "# Save the model state dictionary\n",
    "torch.save(model.state_dict(), file_path)\n",
    "\n",
    "print(\"Model weights saved successfully at:\", file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "816342ba-6dae-4b4f-865c-3faf140eded1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_name = \"model_weight_\" + str(I) + \"_instance_\" + str(scen) + \"_scen.json\"\n",
    "file_path = os.path.join(folder_path, file_name)\n",
    "save_weights_biases_to_json(model, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45910dfb-d297-4363-b150-2b51d53e8753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store dictionaries of data\n",
    "data_dicts = []\n",
    "\n",
    "problem_size = instance_df.shape[1]\n",
    "\n",
    "\n",
    "# Ensure model and data are on the same device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Move model to the selected device\n",
    "model = model.to(device)\n",
    "\n",
    "# Iterate through test loader\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs_instance, inputs_X, inputs_uncern, labels = data\n",
    "        inputs_instance = inputs_instance.to(device)\n",
    "        inputs_X = inputs_X.to(device)\n",
    "        inputs_uncern = inputs_uncern.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(inputs_instance, inputs_X, inputs_uncern)\n",
    "\n",
    "        # Convert outputs and labels to numpy arrays (if needed)\n",
    "        outputs = outputs.cpu().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "        # Iterate through batch\n",
    "        for i in range(len(labels)):\n",
    "            # Prepare a dictionary for row data\n",
    "            row_data = {}\n",
    "            for j in range(problem_size):\n",
    "                row_data['Input_Instance_' + str(j)] = inputs_instance[i][j].item()\n",
    "            for j in range(I):\n",
    "                row_data['Input_X_' + str(j)] = inputs_X[i][j].item()\n",
    "                row_data['Input_Uncern_' + str(j)] = inputs_uncern[i][j].item()\n",
    "            row_data['Predicted_Output'] = outputs[i][0]\n",
    "            row_data['Real_Output'] = labels[i]\n",
    "            \n",
    "            # Append row dictionary to the list\n",
    "            data_dicts.append(row_data)\n",
    "\n",
    "# Create DataFrame from the list of dictionaries\n",
    "test_data_df = pd.DataFrame(data_dicts)\n",
    "test_data_df = pd.concat([test_data_df.iloc[:,:problem_size], test_data_df[sorted(test_data_df.iloc[:,problem_size:])]], axis=1)\n",
    "# # Save DataFrame to a CSV file\n",
    "# data_df.to_csv('test_results_scaled_mini.csv', index=False)\n",
    "\n",
    "# print(\"CSV file saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "004cc9c8-06bf-4776-bdf8-77bd90b19934",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22000, 144)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "239a4a8b-4285-418b-8738-9b884b0b09d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a list to store dictionaries of data\n",
    "data_dicts = []\n",
    "\n",
    "problem_size = instance_df.shape[1]\n",
    "\n",
    "\n",
    "# Ensure model and data are on the same device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Move model to the selected device\n",
    "model = model.to(device)\n",
    "\n",
    "# Iterate through test loader\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        inputs_instance, inputs_X, inputs_uncern, labels = data\n",
    "        inputs_instance = inputs_instance.to(device)\n",
    "        inputs_X = inputs_X.to(device)\n",
    "        inputs_uncern = inputs_uncern.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        outputs = model(inputs_instance, inputs_X, inputs_uncern)\n",
    "\n",
    "        # Convert outputs and labels to numpy arrays (if needed)\n",
    "        outputs = outputs.cpu().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "        # Iterate through batch\n",
    "        for i in range(len(labels)):\n",
    "            # Prepare a dictionary for row data\n",
    "            row_data = {}\n",
    "            for j in range(problem_size):\n",
    "                row_data['Input_Instance_' + str(j)] = inputs_instance[i][j].item()\n",
    "            for j in range(I):\n",
    "                row_data['Input_X_' + str(j)] = inputs_X[i][j].item()\n",
    "                row_data['Input_Uncern_' + str(j)] = inputs_uncern[i][j].item()\n",
    "            row_data['Predicted_Output'] = outputs[i][0]\n",
    "            row_data['Real_Output'] = labels[i]\n",
    "            \n",
    "            # Append row dictionary to the list\n",
    "            data_dicts.append(row_data)\n",
    "\n",
    "# Create DataFrame from the list of dictionaries\n",
    "train_data_df = pd.DataFrame(data_dicts)\n",
    "train_data_df = pd.concat([train_data_df.iloc[:,:problem_size], train_data_df[sorted(train_data_df.iloc[:,problem_size:])]], axis=1)\n",
    "# # Save DataFrame to a CSV file\n",
    "# data_df.to_csv('test_results_scaled_mini.csv', index=False)\n",
    "\n",
    "# print(\"CSV file saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a8c01bc4-3929-42ff-a5bc-b48851fa6f7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input_Instance_0</th>\n",
       "      <th>Input_Instance_1</th>\n",
       "      <th>Input_Instance_2</th>\n",
       "      <th>Input_Instance_3</th>\n",
       "      <th>Input_Instance_4</th>\n",
       "      <th>Input_Instance_5</th>\n",
       "      <th>Input_Instance_6</th>\n",
       "      <th>Input_Instance_7</th>\n",
       "      <th>Input_Instance_8</th>\n",
       "      <th>Input_Instance_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Input_X_2</th>\n",
       "      <th>Input_X_3</th>\n",
       "      <th>Input_X_4</th>\n",
       "      <th>Input_X_5</th>\n",
       "      <th>Input_X_6</th>\n",
       "      <th>Input_X_7</th>\n",
       "      <th>Input_X_8</th>\n",
       "      <th>Input_X_9</th>\n",
       "      <th>Predicted_Output</th>\n",
       "      <th>Real_Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.522343</td>\n",
       "      <td>0.840937</td>\n",
       "      <td>0.273446</td>\n",
       "      <td>0.226863</td>\n",
       "      <td>0.534307</td>\n",
       "      <td>0.872936</td>\n",
       "      <td>0.803643</td>\n",
       "      <td>0.404864</td>\n",
       "      <td>0.468557</td>\n",
       "      <td>0.515224</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.344252</td>\n",
       "      <td>[0.34368682]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.667587</td>\n",
       "      <td>0.603345</td>\n",
       "      <td>0.615207</td>\n",
       "      <td>0.321750</td>\n",
       "      <td>0.679766</td>\n",
       "      <td>0.622413</td>\n",
       "      <td>0.608257</td>\n",
       "      <td>0.772115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.526591</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.297345</td>\n",
       "      <td>[0.29774976]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.852066</td>\n",
       "      <td>0.035834</td>\n",
       "      <td>0.369676</td>\n",
       "      <td>0.589228</td>\n",
       "      <td>0.493904</td>\n",
       "      <td>0.647270</td>\n",
       "      <td>0.130130</td>\n",
       "      <td>0.480853</td>\n",
       "      <td>0.683585</td>\n",
       "      <td>0.780598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.569108</td>\n",
       "      <td>[0.5690927]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.046207</td>\n",
       "      <td>0.077465</td>\n",
       "      <td>0.490825</td>\n",
       "      <td>0.250275</td>\n",
       "      <td>0.693002</td>\n",
       "      <td>0.834935</td>\n",
       "      <td>0.764190</td>\n",
       "      <td>0.053456</td>\n",
       "      <td>0.086031</td>\n",
       "      <td>0.836928</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.554132</td>\n",
       "      <td>[0.55609274]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.590604</td>\n",
       "      <td>0.492968</td>\n",
       "      <td>0.100451</td>\n",
       "      <td>0.753251</td>\n",
       "      <td>0.641162</td>\n",
       "      <td>0.036551</td>\n",
       "      <td>0.597009</td>\n",
       "      <td>0.882112</td>\n",
       "      <td>0.727744</td>\n",
       "      <td>0.055532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.335619</td>\n",
       "      <td>[0.33641803]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87995</th>\n",
       "      <td>0.545245</td>\n",
       "      <td>0.628936</td>\n",
       "      <td>0.092196</td>\n",
       "      <td>0.659909</td>\n",
       "      <td>0.493366</td>\n",
       "      <td>0.635638</td>\n",
       "      <td>0.098929</td>\n",
       "      <td>0.612639</td>\n",
       "      <td>0.257343</td>\n",
       "      <td>0.633411</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.819742</td>\n",
       "      <td>[0.81865495]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87996</th>\n",
       "      <td>0.820210</td>\n",
       "      <td>0.023222</td>\n",
       "      <td>0.382725</td>\n",
       "      <td>0.800134</td>\n",
       "      <td>0.682976</td>\n",
       "      <td>0.345339</td>\n",
       "      <td>0.909329</td>\n",
       "      <td>0.388448</td>\n",
       "      <td>0.844921</td>\n",
       "      <td>0.244721</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.714784</td>\n",
       "      <td>[0.71775025]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87997</th>\n",
       "      <td>0.308201</td>\n",
       "      <td>0.376821</td>\n",
       "      <td>0.125786</td>\n",
       "      <td>0.407443</td>\n",
       "      <td>0.029105</td>\n",
       "      <td>0.938814</td>\n",
       "      <td>0.043374</td>\n",
       "      <td>0.915889</td>\n",
       "      <td>0.667858</td>\n",
       "      <td>0.726472</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.483473</td>\n",
       "      <td>[0.48384356]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87998</th>\n",
       "      <td>0.485027</td>\n",
       "      <td>0.854712</td>\n",
       "      <td>0.197442</td>\n",
       "      <td>0.440022</td>\n",
       "      <td>0.153848</td>\n",
       "      <td>0.041720</td>\n",
       "      <td>0.819249</td>\n",
       "      <td>0.161502</td>\n",
       "      <td>0.704876</td>\n",
       "      <td>0.574145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.688540</td>\n",
       "      <td>[0.688617]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87999</th>\n",
       "      <td>0.239377</td>\n",
       "      <td>0.104594</td>\n",
       "      <td>0.139123</td>\n",
       "      <td>0.207053</td>\n",
       "      <td>0.834190</td>\n",
       "      <td>0.848525</td>\n",
       "      <td>0.037088</td>\n",
       "      <td>0.672478</td>\n",
       "      <td>0.535492</td>\n",
       "      <td>0.632554</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.513004</td>\n",
       "      <td>[0.5105922]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88000 rows  144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Input_Instance_0  Input_Instance_1  Input_Instance_2  Input_Instance_3  \\\n",
       "0              0.522343          0.840937          0.273446          0.226863   \n",
       "1              0.667587          0.603345          0.615207          0.321750   \n",
       "2              0.852066          0.035834          0.369676          0.589228   \n",
       "3              0.046207          0.077465          0.490825          0.250275   \n",
       "4              0.590604          0.492968          0.100451          0.753251   \n",
       "...                 ...               ...               ...               ...   \n",
       "87995          0.545245          0.628936          0.092196          0.659909   \n",
       "87996          0.820210          0.023222          0.382725          0.800134   \n",
       "87997          0.308201          0.376821          0.125786          0.407443   \n",
       "87998          0.485027          0.854712          0.197442          0.440022   \n",
       "87999          0.239377          0.104594          0.139123          0.207053   \n",
       "\n",
       "       Input_Instance_4  Input_Instance_5  Input_Instance_6  Input_Instance_7  \\\n",
       "0              0.534307          0.872936          0.803643          0.404864   \n",
       "1              0.679766          0.622413          0.608257          0.772115   \n",
       "2              0.493904          0.647270          0.130130          0.480853   \n",
       "3              0.693002          0.834935          0.764190          0.053456   \n",
       "4              0.641162          0.036551          0.597009          0.882112   \n",
       "...                 ...               ...               ...               ...   \n",
       "87995          0.493366          0.635638          0.098929          0.612639   \n",
       "87996          0.682976          0.345339          0.909329          0.388448   \n",
       "87997          0.029105          0.938814          0.043374          0.915889   \n",
       "87998          0.153848          0.041720          0.819249          0.161502   \n",
       "87999          0.834190          0.848525          0.037088          0.672478   \n",
       "\n",
       "       Input_Instance_8  Input_Instance_9  ...  Input_X_2  Input_X_3  \\\n",
       "0              0.468557          0.515224  ...        1.0        0.0   \n",
       "1              1.000000          0.526591  ...        1.0        0.0   \n",
       "2              0.683585          0.780598  ...        0.0        1.0   \n",
       "3              0.086031          0.836928  ...        1.0        1.0   \n",
       "4              0.727744          0.055532  ...        0.0        1.0   \n",
       "...                 ...               ...  ...        ...        ...   \n",
       "87995          0.257343          0.633411  ...       -0.0       -0.0   \n",
       "87996          0.844921          0.244721  ...       -0.0       -0.0   \n",
       "87997          0.667858          0.726472  ...       -0.0        1.0   \n",
       "87998          0.704876          0.574145  ...        0.0        1.0   \n",
       "87999          0.535492          0.632554  ...       -0.0        1.0   \n",
       "\n",
       "       Input_X_4  Input_X_5  Input_X_6  Input_X_7  Input_X_8  Input_X_9  \\\n",
       "0            1.0        1.0        1.0        1.0        1.0        1.0   \n",
       "1            1.0        1.0        1.0        1.0        1.0        1.0   \n",
       "2            0.0        0.0       -0.0       -0.0        1.0        1.0   \n",
       "3            1.0        1.0        1.0       -0.0        1.0        1.0   \n",
       "4            1.0        0.0        1.0        1.0        1.0        1.0   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "87995        1.0        1.0       -0.0       -0.0       -0.0        1.0   \n",
       "87996        1.0       -0.0        1.0       -0.0        1.0       -0.0   \n",
       "87997       -0.0        1.0       -0.0        1.0        1.0        1.0   \n",
       "87998        0.0        0.0        1.0        0.0        0.0        0.0   \n",
       "87999        1.0        1.0        1.0        1.0        1.0        1.0   \n",
       "\n",
       "       Predicted_Output   Real_Output  \n",
       "0              0.344252  [0.34368682]  \n",
       "1              0.297345  [0.29774976]  \n",
       "2              0.569108   [0.5690927]  \n",
       "3              0.554132  [0.55609274]  \n",
       "4              0.335619  [0.33641803]  \n",
       "...                 ...           ...  \n",
       "87995          0.819742  [0.81865495]  \n",
       "87996          0.714784  [0.71775025]  \n",
       "87997          0.483473  [0.48384356]  \n",
       "87998          0.688540    [0.688617]  \n",
       "87999          0.513004   [0.5105922]  \n",
       "\n",
       "[88000 rows x 144 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "88d6732b-0ba5-4cfe-9909-1ebabbb9694b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved successfully.\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.concat([train_data_df, test_data_df])\n",
    "file_name = 'post_NN_results_' + str(I) + '_instance_'+ str(scen) +'_scen.csv'\n",
    "file_path =os.path.join(folder_path, file_name)\n",
    "data_df.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"CSV file saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2db100e7-a9a3-4d86-806a-f6c6ba918cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to hook to the forward pass of all layers\n",
    "def activation_hook(name):\n",
    "    def hook(module, input, output):\n",
    "        activated_neurons = torch.relu(output) > 0  # Using ReLU activation function\n",
    "        activations_dict[name] = activated_neurons\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "70a7f92a-c85f-45e4-aa80-191ba98a6e2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'high layers improved NN'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ed682643-9f0f-4a98-b249-c0f2a45d3ce2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# I=10\n",
    "# row = 50\n",
    "#     # Create an instance of your model\n",
    "# model = MyModel()\n",
    "# file_name = \"model_weights_\" + str(I) + \".pth\"\n",
    "# file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "# model.load_state_dict(torch.load(file_path))\n",
    "\n",
    "# # Dictionary to store activated neurons for each layer\n",
    "# activations_dict = {}\n",
    "\n",
    "# # Register the hook to all layers of the model\n",
    "# for name, module in model.named_children():\n",
    "#     module.register_forward_hook(activation_hook(name))\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     output = model(train_dataset.tensors[0][row].reshape(1,-1), train_dataset.tensors[1][row].reshape(1,-1), train_dataset.tensors[2][row].reshape(1,-1))\n",
    "# result = np.concatenate([activations_dict[key].numpy().reshape(-1) for key in ['fc1', 'fc2', 'fc3','fc4']])\n",
    "# # Print the activated neurons for each layer\n",
    "# for layer_name, activated_neurons in activations_dict.items():\n",
    "#     print(f\"Activated neurons for {layer_name}: {activated_neurons}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c98dffc6-dce7-40b2-b31f-f4d701bcc404",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# result = []\n",
    "# n_row = train_dataset.tensors[0].shape[0]\n",
    "# for i in range(0,n_row):\n",
    "#     model = MyModel()\n",
    "#     model.load_state_dict(torch.load(file_path))\n",
    "\n",
    "#     # Dictionary to store activated neurons for each layer\n",
    "#     activations_dict = {}\n",
    "\n",
    "#     # Register the hook to all layers of the model\n",
    "#     for name, module in model.named_children():\n",
    "#         module.register_forward_hook(activation_hook(name))\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         output = model(train_dataset.tensors[0][i].reshape(1,-1), train_dataset.tensors[1][i].reshape(1,-1), train_dataset.tensors[2][i].reshape(1,-1))\n",
    "#     result.append(np.concatenate([activations_dict[key].numpy().reshape(-1) for key in ['fc1', 'fc2', 'fc3', 'fc4']]))\n",
    "# activations = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9de79fd8-f230-4138-ad75-05dd84dd00b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# result_test = []\n",
    "# n_row_t = test_dataset.tensors[0].shape[0]\n",
    "# for i in range(0,n_row_t):\n",
    "#     model = MyModel()\n",
    "#     model.load_state_dict(torch.load(file_path))\n",
    "\n",
    "#     # Dictionary to store activated neurons for each layer\n",
    "#     activations_dict = {}\n",
    "\n",
    "#     # Register the hook to all layers of the model\n",
    "#     for name, module in model.named_children():\n",
    "#         module.register_forward_hook(activation_hook(name))\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         output = model(test_dataset.tensors[0][i].reshape(1,-1), test_dataset.tensors[1][i].reshape(1,-1), test_dataset.tensors[2][i].reshape(1,-1))\n",
    "#     result_test.append(np.concatenate([activations_dict[key].numpy().reshape(-1) for key in ['fc1', 'fc2', 'fc3']]))\n",
    "\n",
    "# activations_test = pd.DataFrame(result_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1aa4ae27-e657-4e0b-9b9c-b850ce5e18be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# act_train = (activations.sum()/train_dataset.tensors[0].shape[0]).to_list()\n",
    "# act_test = (activations_test.sum()/test_dataset.tensors[0].shape[0]).to_list()\n",
    "# # for i in range(len(activations)):\n",
    "# #     print(f\"Train: {round(act_train[i],4)},  Test: {round(act_test[i],4)}\")\n",
    "\n",
    "# for i in range(len(act_train)):\n",
    "#     train_activation = act_train[i]\n",
    "#     test_activation = act_test[i]\n",
    "\n",
    "#     train_text = f\"Train: {round(train_activation, 4)}\"\n",
    "#     test_text = f\"Test: {round(test_activation, 4)}\"\n",
    "\n",
    "#     # Check if activations are 0 and change color accordingly\n",
    "#     if train_activation == 0:\n",
    "#         train_text = f\"\\033[91m{train_text}\\033[0m\"  # Red color\n",
    "#     if test_activation == 0:\n",
    "#         test_text = f\"\\033[91m{test_text}\\033[0m\"  # Red color\n",
    "\n",
    "#     print(train_text, test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13134de-e6bd-4c4a-b35c-a96845d2d656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4623cb9-64e0-49f3-8ac4-a978b9630562",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
